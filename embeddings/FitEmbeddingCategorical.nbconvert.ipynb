{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b903e9-5ed1-4da6-a51c-1faa47f21841",
   "metadata": {},
   "source": [
    "# A symmetric bilinear form for embeddings\n",
    "\n",
    "In this notebook, we train a simple bilinear symmetric model to use it in learnMSA. The task is a categorical classification task where to inputs are pairs of sequences: Query and target. The model should predict for each residual in the query sequence the correct residual of the target (if any) it is aligned to in the reference MSA.\n",
    "\n",
    "Let $x_i,y_j$ where $x$ is the query and $y$ is the target be $d$-dimensional embeddings. The model is\n",
    "\n",
    "$$f(x_i, y_j) = \\frac{\\exp(s_{i,j})} {\\sum_j' \\exp(s_{i,j'})} $$\n",
    "\n",
    "with $s_{i,j} = x_i^T R R^T y_j + b$.\n",
    "\n",
    "where $R \\in \\mathbb{R}^{d \\times k}$ is a parameter matrix and $k<d$ can be controlled for dimensionality reduction. $b$ is a scalar bias.\n",
    "\n",
    "When used in learnMSA, we can compute embedding-based emission probabilities for a $k$-dimensional match kernel $m_i$ and an $d$-dimensional embeddings $x_j$ with pre-trained $R$ and $b$ like so:\n",
    "\n",
    "$$P(x_j \\mid m_i) = \\frac{\\exp(s'_{i,j})} {\\sum_j' \\exp(s'_{i,j'})}$$\n",
    "\n",
    "with $s'_{i,j} = x_j R m_i + b$.\n",
    "\n",
    "In this case only $m$ is learned and $R$ and $b$ are fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092e1167-3aca-4239-ae1b-21fe2856988f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:06:23.148039Z",
     "iopub.status.busy": "2023-05-15T06:06:23.147730Z",
     "iopub.status.idle": "2023-05-15T06:06:34.799139Z",
     "shell.execute_reply": "2023-05-15T06:06:34.798255Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 06:06:23.881626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-15 06:06:23.881674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-15 06:06:31.138803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-15 06:06:31.138841: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-15 06:06:31.138863: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (node384): /proc/driver/nvidia/version does not exist\n",
      "2023-05-15 06:06:31.139034: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../learnMSA')\n",
    "from learnMSA import msa_hmm\n",
    "import os\n",
    "from BilinearSymmetric import SymmetricBilinearReduction, BackgroundEmbedding\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71309a30-3a2f-492a-bd15-cc6b47b8cedd",
   "metadata": {},
   "source": [
    "## Data preparation Task 2: Categorical classification of embedding\n",
    "\n",
    "Use Pfams clan hierarchy as the basis for train/test splitting and batch sampling. A clan is a collection of related Pfam entries. The relationship may be defined by similarity of sequence, structure or profile-HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db1c60e-7a78-4e94-a829-f507a9cc7307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:06:34.803595Z",
     "iopub.status.busy": "2023-05-15T06:06:34.803263Z",
     "iopub.status.idle": "2023-05-15T06:06:34.935736Z",
     "shell.execute_reply": "2023-05-15T06:06:34.934831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF00001\tCL0192\tGPCR_A\t7tm_1\t7 transmembrane receptor (rhodopsin family)\n",
      "PF00002\tCL0192\tGPCR_A\t7tm_2\t7 transmembrane receptor (Secretin family)\n",
      "PF00003\tCL0192\tGPCR_A\t7tm_3\t7 transmembrane sweet-taste receptor of 3 GCPR\n",
      "PF00004\tCL0023\tP-loop_NTPase\tAAA\tATPase family associated with various cellular activities (AAA)\n",
      "PF00005\tCL0023\tP-loop_NTPase\tABC_tran\tABC transporter\n",
      "PF00006\tCL0023\tP-loop_NTPase\tATP-synt_ab\tATP synthase alpha/beta family, nucleotide-binding domain\n",
      "PF00007\tCL0079\tCystine-knot\tCys_knot\tCystine-knot domain\n",
      "PF00008\tCL0001\tEGF\tEGF\tEGF-like domain\n",
      "PF00009\tCL0023\tP-loop_NTPase\tGTP_EFTU\tElongation factor Tu GTP binding domain\n",
      "PF00010\t\t\tHLH\tHelix-loop-helix DNA-binding domain\n"
     ]
    }
   ],
   "source": [
    "!head ../../PFAM/Pfam-A.clans.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db49c911-6ea4-4984-9036-977589f03cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:06:34.939241Z",
     "iopub.status.busy": "2023-05-15T06:06:34.939078Z",
     "iopub.status.idle": "2023-05-15T06:06:34.970044Z",
     "shell.execute_reply": "2023-05-15T06:06:34.969176Z"
    }
   },
   "outputs": [],
   "source": [
    "clans_df = pd.read_csv(\"../../PFAM/Pfam-A.clans.tsv\", header=None, sep=\"\\t\")\n",
    "clans_df[1] = clans_df[1].fillna(clans_df[0]) #families with no clan become their own clans\n",
    "clans_df.set_index(0, inplace=True)\n",
    "clans_df.drop([2,3,4], axis=1, inplace=True)\n",
    "clans_df.rename(columns={1 : \"clan\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40af9da0-0c31-47f5-8421-200bc10f9997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:06:34.973891Z",
     "iopub.status.busy": "2023-05-15T06:06:34.973271Z",
     "iopub.status.idle": "2023-05-15T06:06:34.980044Z",
     "shell.execute_reply": "2023-05-15T06:06:34.979394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CL0192'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clans_df.loc[\"PF00001\"].clan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edc3b57-e339-42e3-9825-4da22a5b158b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:06:34.983293Z",
     "iopub.status.busy": "2023-05-15T06:06:34.983149Z",
     "iopub.status.idle": "2023-05-15T06:08:27.971334Z",
     "shell.execute_reply": "2023-05-15T06:08:27.970525Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11865 clans in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clan</th>\n",
       "      <th>fasta_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PF00001</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>13877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00002</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>12061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00003</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>12652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00004</th>\n",
       "      <td>CL0023</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00005</th>\n",
       "      <td>CL0023</td>\n",
       "      <td>13836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clan  fasta_index\n",
       "0                           \n",
       "PF00001  CL0192        13877\n",
       "PF00002  CL0192        12061\n",
       "PF00003  CL0192        12652\n",
       "PF00004  CL0023         6410\n",
       "PF00005  CL0023        13836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(77)\n",
    "\n",
    "#sequences longer than this value were truncated by the LM \n",
    "#todo: redo the embeddings without truncation\n",
    "#for simplicity we omit families with at least one sequence longer than this value (0.3% of all families)\n",
    "lm_model_truncation_value = 1022\n",
    "\n",
    "def get_family(filepath):\n",
    "    return \".\".join(os.path.basename(filepath).split(\".\")[:-1])\n",
    "\n",
    "#load all fasta files\n",
    "#(takes a while)\n",
    "datasets = \"../../PFAM/alignments/\"\n",
    "ext = \".fasta\"\n",
    "\n",
    "clans_df[\"fasta_index\"] = np.nan\n",
    "\n",
    "# load all ref alignments\n",
    "fasta_files = []\n",
    "to_drop = []\n",
    "truncated_clans = set()\n",
    "for file in os.listdir(datasets):\n",
    "    if file.endswith(ext):\n",
    "        family = \".\".join(file.split(\".\")[:-1])\n",
    "        fasta = msa_hmm.fasta.Fasta(datasets+file, aligned=True, single_seq_ok=True)\n",
    "        #omit families with only one sequence or families with at least one truncated sequence\n",
    "        if fasta.num_seq == 1 or np.any(fasta.seq_lens > lm_model_truncation_value):\n",
    "            to_drop.append(family)\n",
    "            truncated_clans.add(clans_df.loc[family].clan)\n",
    "            continue\n",
    "        fasta_files.append(fasta)\n",
    "        clans_df.loc[family, \"fasta_index\"] = len(fasta_files)-1\n",
    "        \n",
    "#drop families\n",
    "clans_df = clans_df.drop(to_drop, axis=0)\n",
    "\n",
    "assert not clans_df.isna().values.any()\n",
    "clans_df = clans_df.astype({\"fasta_index\": \"int32\"})\n",
    "\n",
    "#preprocessing\n",
    "seq_lens, starting_pos, seq_pos_to_column = {}, {}, {}\n",
    "for f in fasta_files:\n",
    "    family = get_family(f.filename)\n",
    "    seq_lens[family] = f.seq_lens\n",
    "    starting_pos[family] = f.starting_pos\n",
    "    seq_pos_to_column[family] = f.membership_targets\n",
    "\n",
    "unique_clans = clans_df.clan.unique()\n",
    "num_clans = unique_clans.size\n",
    "print(f\"{num_clans} clans in total\")\n",
    "clans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760c853c-302c-4eba-8b29-26bd4f25605e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:08:27.974844Z",
     "iopub.status.busy": "2023-05-15T06:08:27.974694Z",
     "iopub.status.idle": "2023-05-15T06:50:49.674959Z",
     "shell.execute_reply": "2023-05-15T06:50:49.671594Z"
    }
   },
   "outputs": [],
   "source": [
    "prot_model = \"esm\"\n",
    "\n",
    "def load(clan):\n",
    "    clan_families = clans_df[clans_df.clan == clan]\n",
    "    return {family : np.load(f\"{prot_model}/pfam/{family}.npy\").astype(np.float16) for family in clan_families.index}\n",
    "\n",
    "# warning, this loads ~1.8TB directly into memory\n",
    "with Pool(8) as p:\n",
    "    clan_embeddings = p.map(load, unique_clans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f221db64-413e-4e9c-91e5-369dc1e8c657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:50:49.680713Z",
     "iopub.status.busy": "2023-05-15T06:50:49.680539Z",
     "iopub.status.idle": "2023-05-15T06:50:49.695862Z",
     "shell.execute_reply": "2023-05-15T06:50:49.695179Z"
    }
   },
   "outputs": [],
   "source": [
    "for _,emb in clan_embeddings[0].items():\n",
    "    emb_dim = emb.shape[-1]\n",
    "clan_sizes = np.array([len(emb) for emb in clan_embeddings])\n",
    "\n",
    "def _get_features_labels(emb, lens, start, pos_to_col, rand):\n",
    "    n = lens.size\n",
    "    i = int(np.floor(rand * n))\n",
    "    s = start[i]\n",
    "    t = s + lens[i]\n",
    "    return emb[s:t], pos_to_col[s:t], lens[i]\n",
    "\n",
    "def make_dataset(clans, batch_size):\n",
    "    def _gen_inputs():\n",
    "        \"\"\" Generates a batch of training examples where one example is generated as:\n",
    "            1. Sample a random clan\n",
    "            2. Sample a random family from this clan\n",
    "            3. Sample 2 random sequences from this family\n",
    "            4. Compute the label matrix that has the 2 sequence lengths as rows/columns \n",
    "                and holds a 1 where residues share the same alignment column.\n",
    "        Returns:\n",
    "            (query_seqs, target_seqs), labels\n",
    "            Where query_seqs and target_seqs are batches of embedded sequences (b, L1, d), (b, L2, d) \n",
    "            and labels are of shape (b, L1, L2)\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            #sample clan\n",
    "            batch_clans = np.random.choice(clans, size=batch_size)\n",
    "            #sample family\n",
    "            rand_family = np.random.rand(batch_size)\n",
    "            batch_families = np.floor(rand_family * clan_sizes[batch_clans]).astype(batch_clans.dtype)\n",
    "            #sample sequences (with replacement for speed)\n",
    "            rand_seq = np.random.rand(batch_size, 2)\n",
    "            emb1, emb2, labels = [], [], []\n",
    "            max_len_1, max_len_2 = -1, -1\n",
    "            for c,f,r in zip(batch_clans, batch_families, rand_seq):\n",
    "                f_name = list(clan_embeddings[c].keys())[f]\n",
    "                emb = clan_embeddings[c][f_name]\n",
    "                lens = seq_lens[f_name]\n",
    "                start = starting_pos[f_name]\n",
    "                pos_to_col = seq_pos_to_column[f_name]\n",
    "                assert emb.shape[0] == pos_to_col.size\n",
    "                e1, c1, l1 = _get_features_labels(emb, lens, start, pos_to_col, r[0])\n",
    "                e2, c2, l2 = _get_features_labels(emb, lens, start, pos_to_col, r[1])\n",
    "                max_len_1 = max(max_len_1, l1)\n",
    "                max_len_2 = max(max_len_2, l2)\n",
    "                emb1.append(e1)\n",
    "                emb2.append(e2)\n",
    "                labels.append((c1[:, np.newaxis] == c2[np.newaxis, :]).astype(np.float32))\n",
    "            #merge everything in padded tensors\n",
    "            batched_emb1 = np.zeros((batch_size, max_len_1, emb_dim), dtype=np.float32)\n",
    "            batched_emb2 = np.zeros((batch_size, max_len_2, emb_dim), dtype=np.float32)\n",
    "            batched_labels = np.zeros((batch_size, max_len_1, max_len_2), dtype=np.float32)\n",
    "            for i, (e1, e2, label) in enumerate(zip(emb1, emb2, labels)):\n",
    "                batched_emb1[i, :e1.shape[0]] = e1\n",
    "                batched_emb2[i, :e2.shape[0]] = e2\n",
    "                batched_labels[i, :e1.shape[0], :e2.shape[0]] = label\n",
    "            yield (batched_emb1, batched_emb2), batched_labels\n",
    "            \n",
    "    output_signature = ((tf.TensorSpec(shape=(batch_size, None, emb_dim), dtype=tf.float32), \n",
    "                         tf.TensorSpec(shape=(batch_size, None, emb_dim), dtype=tf.float32)), \n",
    "                            tf.TensorSpec(shape=(batch_size, None, None), dtype=tf.float32))\n",
    "    ds = tf.data.Dataset.from_generator(_gen_inputs, output_signature = output_signature)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae050f52-2c6e-41f2-b2fa-8d2c02cbc7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:50:49.698972Z",
     "iopub.status.busy": "2023-05-15T06:50:49.698833Z",
     "iopub.status.idle": "2023-05-15T06:50:49.704261Z",
     "shell.execute_reply": "2023-05-15T06:50:49.703651Z"
    }
   },
   "outputs": [],
   "source": [
    "#split by clan, test on kept back clans\n",
    "test_p = 0.15\n",
    "val_p = 0.15\n",
    "assert test_p + val_p < 1\n",
    "num_test = int(num_clans * test_p)\n",
    "num_val = int(num_clans * val_p)\n",
    "num_train = num_clans - num_test\n",
    "a = np.arange(num_clans)\n",
    "np.random.shuffle(a)\n",
    "test_clans = a[:num_test]\n",
    "val_clans = a[num_test:num_test+num_val]\n",
    "train_clans = a[num_test+num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee531ad-9b2d-4fa2-8d7a-1557c882ec80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:50:49.708212Z",
     "iopub.status.busy": "2023-05-15T06:50:49.707961Z",
     "iopub.status.idle": "2023-05-15T06:50:50.230641Z",
     "shell.execute_reply": "2023-05-15T06:50:50.229700Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_ds = make_dataset(test_clans, batch_size)\n",
    "val_ds = make_dataset(val_clans, batch_size)\n",
    "train_ds = make_dataset(train_clans, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5f6bc-0626-401b-aed6-d5fb2759f124",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a39cff3d-2e1a-4673-b4f3-025b29cfd667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:50:50.234496Z",
     "iopub.status.busy": "2023-05-15T06:50:50.234261Z",
     "iopub.status.idle": "2023-05-15T06:50:50.242100Z",
     "shell.execute_reply": "2023-05-15T06:50:50.241287Z"
    }
   },
   "outputs": [],
   "source": [
    "def masked_crossentropy(y_true, y_pred):\n",
    "    mask = tf.reduce_any(tf.not_equal(y_true, 0), -1)\n",
    "    y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "    cee = tf.keras.metrics.categorical_crossentropy(y_true_masked, y_pred_masked)\n",
    "    return tf.reduce_mean(cee)\n",
    "    \n",
    "def make_model(reduced_dim = 256, dropout = 0.2):\n",
    "    # input to the training pipeline are pairs of embeddings\n",
    "    emb1 = tf.keras.layers.Input(shape=(None, emb_dim))\n",
    "    emb2 = tf.keras.layers.Input(shape=(None, emb_dim))\n",
    "\n",
    "    # outputs are homology probabilities \n",
    "    output = SymmetricBilinearReduction(reduced_dim,\n",
    "                                        dropout, \n",
    "                                        use_attention_scores = True)(emb1, emb2)\n",
    "\n",
    "    # construct a model and compile for a standard binary classification task\n",
    "    model = tf.keras.models.Model(inputs=[emb1, emb2], outputs=output)\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    model.compile(loss=masked_crossentropy, \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45ecd2a-736e-40de-b5f5-6fd7025028b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T06:50:50.245694Z",
     "iopub.status.busy": "2023-05-15T06:50:50.245444Z",
     "iopub.status.idle": "2023-05-15T21:38:37.215193Z",
     "shell.execute_reply": "2023-05-15T21:38:37.214459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 5432s 543ms/step - loss: 1.5096 - categorical_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 5453s 545ms/step - loss: 1.3339 - categorical_accuracy: 0.9131\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 5371s 537ms/step - loss: 1.2729 - categorical_accuracy: 0.9162\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 5343s 534ms/step - loss: 1.2586 - categorical_accuracy: 0.9171\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 5316s 532ms/step - loss: 1.2469 - categorical_accuracy: 0.9177\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 5302s 530ms/step - loss: 1.2515 - categorical_accuracy: 0.9174\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 5276s 528ms/step - loss: 1.2468 - categorical_accuracy: 0.9176\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 5212s 521ms/step - loss: 1.2490 - categorical_accuracy: 0.9170\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 5265s 526ms/step - loss: 1.2436 - categorical_accuracy: 0.9178\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 5295s 530ms/step - loss: 1.2479 - categorical_accuracy: 0.9179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_64_04/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_64_04/assets\n"
     ]
    }
   ],
   "source": [
    "full_ds = make_dataset(a, batch_size)\n",
    "final_model1 = make_model(reduced_dim = 64, dropout = 0.4)\n",
    "final_model1.fit(full_ds, epochs=10, steps_per_epoch=10000)\n",
    "final_model1.save(f\"{prot_model}/bilinear_form_model_pfam_attention_64_04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cadd8032-4fbe-4adf-af54-d603f4f8bf1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T21:38:37.221255Z",
     "iopub.status.busy": "2023-05-15T21:38:37.221083Z",
     "iopub.status.idle": "2023-05-16T12:37:04.146111Z",
     "shell.execute_reply": "2023-05-16T12:37:04.145123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 5260s 526ms/step - loss: 1.1690 - categorical_accuracy: 0.9256\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 5378s 538ms/step - loss: 0.9687 - categorical_accuracy: 0.9326\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 5418s 542ms/step - loss: 0.9017 - categorical_accuracy: 0.9353\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 5443s 544ms/step - loss: 0.8841 - categorical_accuracy: 0.9360\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 5434s 543ms/step - loss: 0.8748 - categorical_accuracy: 0.9366\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 5397s 540ms/step - loss: 0.8742 - categorical_accuracy: 0.9364\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 5392s 539ms/step - loss: 0.8721 - categorical_accuracy: 0.9365\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 5395s 540ms/step - loss: 0.8763 - categorical_accuracy: 0.9365\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 5385s 538ms/step - loss: 0.8718 - categorical_accuracy: 0.9365\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 5403s 540ms/step - loss: 0.8694 - categorical_accuracy: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_128_02/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_128_02/assets\n"
     ]
    }
   ],
   "source": [
    "final_model2 = make_model(reduced_dim = 128, dropout = 0.2)\n",
    "final_model2.fit(full_ds, epochs=10, steps_per_epoch=10000)\n",
    "final_model2.save(f\"{prot_model}/bilinear_form_model_pfam_attention_128_02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528ad63d-a567-440b-b743-4b0a26e5a690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-16T12:37:04.151733Z",
     "iopub.status.busy": "2023-05-16T12:37:04.151525Z",
     "iopub.status.idle": "2023-05-17T03:27:09.181898Z",
     "shell.execute_reply": "2023-05-17T03:27:09.181059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 5308s 531ms/step - loss: 1.4304 - categorical_accuracy: 0.9129\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 5340s 534ms/step - loss: 1.1583 - categorical_accuracy: 0.9225\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 5397s 540ms/step - loss: 1.0851 - categorical_accuracy: 0.9262\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 5414s 541ms/step - loss: 1.0543 - categorical_accuracy: 0.9277\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 5400s 540ms/step - loss: 1.0464 - categorical_accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 5410s 541ms/step - loss: 1.0454 - categorical_accuracy: 0.9280\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 5428s 543ms/step - loss: 1.0402 - categorical_accuracy: 0.9283\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 5293s 529ms/step - loss: 1.0385 - categorical_accuracy: 0.9284\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 5204s 520ms/step - loss: 1.0402 - categorical_accuracy: 0.9283\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 5209s 521ms/step - loss: 1.0430 - categorical_accuracy: 0.9280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_128_04/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention_128_04/assets\n"
     ]
    }
   ],
   "source": [
    "final_model3 = make_model(reduced_dim = 128, dropout = 0.4)\n",
    "final_model3.fit(full_ds, epochs=10, steps_per_epoch=10000)\n",
    "final_model3.save(f\"{prot_model}/bilinear_form_model_pfam_attention_128_04\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b903e9-5ed1-4da6-a51c-1faa47f21841",
   "metadata": {},
   "source": [
    "# A symmetric bilinear form for embeddings\n",
    "\n",
    "In this notebook, we train a simple bilinear symmetric model to use it in learnMSA. The task is a categorical classification task where to inputs are pairs of sequences: Query and target. The model should predict for each residual in the query sequence the correct residual of the target (if any) it is aligned to in the reference MSA.\n",
    "\n",
    "Let $x_i,y_j$ where $x$ is the query and $y$ is the target be $d$-dimensional embeddings. The model is\n",
    "\n",
    "$$f(x_i, y_j) = \\frac{\\exp(s_{i,j})} {\\sum_j' \\exp(s_{i,j'})} $$\n",
    "\n",
    "with $s_{i,j} = x_i^T R R^T y_j + b$.\n",
    "\n",
    "where $R \\in \\mathbb{R}^{d \\times k}$ is a parameter matrix and $k<d$ can be controlled for dimensionality reduction. $b$ is a scalar bias.\n",
    "\n",
    "When used in learnMSA, we can compute embedding-based emission probabilities for a $k$-dimensional match kernel $m_i$ and an $d$-dimensional embeddings $x_j$ with pre-trained $R$ and $b$ like so:\n",
    "\n",
    "$$P(x_j \\mid m_i) = \\frac{\\exp(s'_{i,j})} {\\sum_j' \\exp(s'_{i,j'})}$$\n",
    "\n",
    "with $s'_{i,j} = x_j R m_i + b$.\n",
    "\n",
    "In this case only $m$ is learned and $R$ and $b$ are fixed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092e1167-3aca-4239-ae1b-21fe2856988f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 08:44:21.979238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-12 08:44:22.440135: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/conda/lib\n",
      "2023-05-12 08:44:22.440335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/conda/lib\n",
      "2023-05-12 08:44:22.440347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../../learnMSA')\n",
    "from learnMSA import msa_hmm\n",
    "import os\n",
    "from BilinearSymmetric import SymmetricBilinearReduction, BackgroundEmbedding\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import io\n",
    "import os\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71309a30-3a2f-492a-bd15-cc6b47b8cedd",
   "metadata": {},
   "source": [
    "## Data preparation Task 2: Categorical classification of embedding\n",
    "\n",
    "Use Pfams clan hierarchy as the basis for train/test splitting and batch sampling. A clan is a collection of related Pfam entries. The relationship may be defined by similarity of sequence, structure or profile-HMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db1c60e-7a78-4e94-a829-f507a9cc7307",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:25:20.464335Z",
     "iopub.status.busy": "2023-05-11T05:25:20.463999Z",
     "iopub.status.idle": "2023-05-11T05:25:20.593761Z",
     "shell.execute_reply": "2023-05-11T05:25:20.592836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PF00001\tCL0192\tGPCR_A\t7tm_1\t7 transmembrane receptor (rhodopsin family)\n",
      "PF00002\tCL0192\tGPCR_A\t7tm_2\t7 transmembrane receptor (Secretin family)\n",
      "PF00003\tCL0192\tGPCR_A\t7tm_3\t7 transmembrane sweet-taste receptor of 3 GCPR\n",
      "PF00004\tCL0023\tP-loop_NTPase\tAAA\tATPase family associated with various cellular activities (AAA)\n",
      "PF00005\tCL0023\tP-loop_NTPase\tABC_tran\tABC transporter\n",
      "PF00006\tCL0023\tP-loop_NTPase\tATP-synt_ab\tATP synthase alpha/beta family, nucleotide-binding domain\n",
      "PF00007\tCL0079\tCystine-knot\tCys_knot\tCystine-knot domain\n",
      "PF00008\tCL0001\tEGF\tEGF\tEGF-like domain\n",
      "PF00009\tCL0023\tP-loop_NTPase\tGTP_EFTU\tElongation factor Tu GTP binding domain\n",
      "PF00010\t\t\tHLH\tHelix-loop-helix DNA-binding domain\n"
     ]
    }
   ],
   "source": [
    "!head ../../PFAM/Pfam-A.clans.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db49c911-6ea4-4984-9036-977589f03cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:25:20.597977Z",
     "iopub.status.busy": "2023-05-11T05:25:20.597619Z",
     "iopub.status.idle": "2023-05-11T05:25:20.627612Z",
     "shell.execute_reply": "2023-05-11T05:25:20.626758Z"
    }
   },
   "outputs": [],
   "source": [
    "clans_df = pd.read_csv(\"../../PFAM/Pfam-A.clans.tsv\", header=None, sep=\"\\t\")\n",
    "clans_df[1] = clans_df[1].fillna(clans_df[0]) #families with no clan become their own clans\n",
    "clans_df.set_index(0, inplace=True)\n",
    "clans_df.drop([2,3,4], axis=1, inplace=True)\n",
    "clans_df.rename(columns={1 : \"clan\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40af9da0-0c31-47f5-8421-200bc10f9997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:25:20.631144Z",
     "iopub.status.busy": "2023-05-11T05:25:20.630897Z",
     "iopub.status.idle": "2023-05-11T05:25:20.637079Z",
     "shell.execute_reply": "2023-05-11T05:25:20.636450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CL0192'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clans_df.loc[\"PF00001\"].clan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edc3b57-e339-42e3-9825-4da22a5b158b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:25:20.640409Z",
     "iopub.status.busy": "2023-05-11T05:25:20.640180Z",
     "iopub.status.idle": "2023-05-11T05:27:08.694443Z",
     "shell.execute_reply": "2023-05-11T05:27:08.693589Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11865 clans in total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clan</th>\n",
       "      <th>fasta_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PF00001</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>13877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00002</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>12061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00003</th>\n",
       "      <td>CL0192</td>\n",
       "      <td>12652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00004</th>\n",
       "      <td>CL0023</td>\n",
       "      <td>6410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PF00005</th>\n",
       "      <td>CL0023</td>\n",
       "      <td>13836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           clan  fasta_index\n",
       "0                           \n",
       "PF00001  CL0192        13877\n",
       "PF00002  CL0192        12061\n",
       "PF00003  CL0192        12652\n",
       "PF00004  CL0023         6410\n",
       "PF00005  CL0023        13836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(77)\n",
    "\n",
    "#sequences longer than this value were truncated by the LM \n",
    "#todo: redo the embeddings without truncation\n",
    "#for simplicity we omit families with at least one sequence longer than this value (0.3% of all families)\n",
    "lm_model_truncation_value = 1022\n",
    "\n",
    "def get_family(filepath):\n",
    "    return \".\".join(os.path.basename(filepath).split(\".\")[:-1])\n",
    "\n",
    "#load all fasta files\n",
    "#(takes a while)\n",
    "datasets = \"../../PFAM/alignments/\"\n",
    "ext = \".fasta\"\n",
    "\n",
    "clans_df[\"fasta_index\"] = np.nan\n",
    "\n",
    "# load all ref alignments\n",
    "fasta_files = []\n",
    "to_drop = []\n",
    "truncated_clans = set()\n",
    "for file in os.listdir(datasets):\n",
    "    if file.endswith(ext):\n",
    "        family = \".\".join(file.split(\".\")[:-1])\n",
    "        fasta = msa_hmm.fasta.Fasta(datasets+file, aligned=True, single_seq_ok=True)\n",
    "        #omit families with only one sequence or families with at least one truncated sequence\n",
    "        if fasta.num_seq == 1 or np.any(fasta.seq_lens > lm_model_truncation_value):\n",
    "            to_drop.append(family)\n",
    "            truncated_clans.add(clans_df.loc[family].clan)\n",
    "            continue\n",
    "        fasta_files.append(fasta)\n",
    "        clans_df.loc[family, \"fasta_index\"] = len(fasta_files)-1\n",
    "        \n",
    "#drop families\n",
    "clans_df = clans_df.drop(to_drop, axis=0)\n",
    "\n",
    "assert not clans_df.isna().values.any()\n",
    "clans_df = clans_df.astype({\"fasta_index\": \"int32\"})\n",
    "\n",
    "#preprocessing\n",
    "seq_lens, starting_pos, seq_pos_to_column = {}, {}, {}\n",
    "for f in fasta_files:\n",
    "    family = get_family(f.filename)\n",
    "    seq_lens[family] = f.seq_lens\n",
    "    starting_pos[family] = f.starting_pos\n",
    "    seq_pos_to_column[family] = f.membership_targets\n",
    "\n",
    "unique_clans = clans_df.clan.unique()\n",
    "num_clans = unique_clans.size\n",
    "print(f\"{num_clans} clans in total\")\n",
    "clans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760c853c-302c-4eba-8b29-26bd4f25605e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T05:27:08.697818Z",
     "iopub.status.busy": "2023-05-11T05:27:08.697660Z",
     "iopub.status.idle": "2023-05-11T06:09:52.797867Z",
     "shell.execute_reply": "2023-05-11T06:09:52.794550Z"
    }
   },
   "outputs": [],
   "source": [
    "prot_model = \"esm\"\n",
    "\n",
    "def load(clan):\n",
    "    clan_families = clans_df[clans_df.clan == clan]\n",
    "    return {family : np.load(f\"{prot_model}/pfam/{family}.npy\").astype(np.float16) for family in clan_families.index}\n",
    "\n",
    "# warning, this loads ~1.8TB directly into memory\n",
    "with Pool(8) as p:\n",
    "    clan_embeddings = p.map(load, unique_clans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f221db64-413e-4e9c-91e5-369dc1e8c657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:09:52.804004Z",
     "iopub.status.busy": "2023-05-11T06:09:52.803831Z",
     "iopub.status.idle": "2023-05-11T06:09:52.817478Z",
     "shell.execute_reply": "2023-05-11T06:09:52.817029Z"
    }
   },
   "outputs": [],
   "source": [
    "for _,emb in clan_embeddings[0].items():\n",
    "    emb_dim = emb.shape[-1]\n",
    "clan_sizes = np.array([len(emb) for emb in clan_embeddings])\n",
    "\n",
    "def _get_features_labels(emb, lens, start, pos_to_col, rand):\n",
    "    n = lens.size\n",
    "    i = int(np.floor(rand * n))\n",
    "    s = start[i]\n",
    "    t = s + lens[i]\n",
    "    return emb[s:t], pos_to_col[s:t], lens[i]\n",
    "\n",
    "def make_dataset(clans, batch_size):\n",
    "    def _gen_inputs():\n",
    "        \"\"\" Generates a batch of training examples where one example is generated as:\n",
    "            1. Sample a random clan\n",
    "            2. Sample a random family from this clan\n",
    "            3. Sample 2 random sequences from this family\n",
    "            4. Compute the label matrix that has the 2 sequence lengths as rows/columns \n",
    "                and holds a 1 where residues share the same alignment column.\n",
    "        Returns:\n",
    "            (query_seqs, target_seqs), labels\n",
    "            Where query_seqs and target_seqs are batches of embedded sequences (b, L1, d), (b, L2, d) \n",
    "            and labels are of shape (b, L1, L2)\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            #sample clan\n",
    "            batch_clans = np.random.choice(clans, size=batch_size)\n",
    "            #sample family\n",
    "            rand_family = np.random.rand(batch_size)\n",
    "            batch_families = np.floor(rand_family * clan_sizes[batch_clans]).astype(batch_clans.dtype)\n",
    "            #sample sequences (with replacement for speed)\n",
    "            rand_seq = np.random.rand(batch_size, 2)\n",
    "            emb1, emb2, labels = [], [], []\n",
    "            max_len_1, max_len_2 = -1, -1\n",
    "            for c,f,r in zip(batch_clans, batch_families, rand_seq):\n",
    "                f_name = list(clan_embeddings[c].keys())[f]\n",
    "                emb = clan_embeddings[c][f_name]\n",
    "                lens = seq_lens[f_name]\n",
    "                start = starting_pos[f_name]\n",
    "                pos_to_col = seq_pos_to_column[f_name]\n",
    "                assert emb.shape[0] == pos_to_col.size\n",
    "                e1, c1, l1 = _get_features_labels(emb, lens, start, pos_to_col, r[0])\n",
    "                e2, c2, l2 = _get_features_labels(emb, lens, start, pos_to_col, r[1])\n",
    "                max_len_1 = max(max_len_1, l1)\n",
    "                max_len_2 = max(max_len_2, l2)\n",
    "                emb1.append(e1)\n",
    "                emb2.append(e2)\n",
    "                labels.append((c1[:, np.newaxis] == c2[np.newaxis, :]).astype(np.float32))\n",
    "            #merge everything in padded tensors\n",
    "            batched_emb1 = np.zeros((batch_size, max_len_1, emb_dim), dtype=np.float32)\n",
    "            batched_emb2 = np.zeros((batch_size, max_len_2, emb_dim), dtype=np.float32)\n",
    "            batched_labels = np.zeros((batch_size, max_len_1, max_len_2), dtype=np.float32)\n",
    "            for i, (e1, e2, label) in enumerate(zip(emb1, emb2, labels)):\n",
    "                batched_emb1[i, :e1.shape[0]] = e1\n",
    "                batched_emb2[i, :e2.shape[0]] = e2\n",
    "                batched_labels[i, :e1.shape[0], :e2.shape[0]] = label\n",
    "            yield (batched_emb1, batched_emb2), batched_labels\n",
    "            \n",
    "    output_signature = ((tf.TensorSpec(shape=(batch_size, None, emb_dim), dtype=tf.float32), \n",
    "                         tf.TensorSpec(shape=(batch_size, None, emb_dim), dtype=tf.float32)), \n",
    "                            tf.TensorSpec(shape=(batch_size, None, None), dtype=tf.float32))\n",
    "    ds = tf.data.Dataset.from_generator(_gen_inputs, output_signature = output_signature)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae050f52-2c6e-41f2-b2fa-8d2c02cbc7f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:09:52.819348Z",
     "iopub.status.busy": "2023-05-11T06:09:52.819132Z",
     "iopub.status.idle": "2023-05-11T06:09:52.824007Z",
     "shell.execute_reply": "2023-05-11T06:09:52.823590Z"
    }
   },
   "outputs": [],
   "source": [
    "#split by clan, test on kept back clans\n",
    "test_p = 0.15\n",
    "val_p = 0.15\n",
    "assert test_p + val_p < 1\n",
    "num_test = int(num_clans * test_p)\n",
    "num_val = int(num_clans * val_p)\n",
    "num_train = num_clans - num_test\n",
    "a = np.arange(num_clans)\n",
    "np.random.shuffle(a)\n",
    "test_clans = a[:num_test]\n",
    "val_clans = a[num_test:num_test+num_val]\n",
    "train_clans = a[num_test+num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee531ad-9b2d-4fa2-8d7a-1557c882ec80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:09:52.825769Z",
     "iopub.status.busy": "2023-05-11T06:09:52.825632Z",
     "iopub.status.idle": "2023-05-11T06:09:53.331355Z",
     "shell.execute_reply": "2023-05-11T06:09:53.330404Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_ds = make_dataset(test_clans, batch_size)\n",
    "val_ds = make_dataset(val_clans, batch_size)\n",
    "train_ds = make_dataset(train_clans, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5f6bc-0626-401b-aed6-d5fb2759f124",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39cff3d-2e1a-4673-b4f3-025b29cfd667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masked_crossentropy(y_true, y_pred):\n",
    "    mask = tf.reduce_any(tf.not_equal(y_true, 0), -1)\n",
    "    y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "    y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "    cee = tf.keras.metrics.categorical_crossentropy(y_true_masked, y_pred_masked)\n",
    "    return tf.reduce_mean(cee)\n",
    "    \n",
    "def make_model(reduced_dim = 256, dropout = 0.2):\n",
    "    # input to the training pipeline are pairs of embeddings\n",
    "    emb1 = tf.keras.layers.Input(shape=(None, emb_dim))\n",
    "    emb2 = tf.keras.layers.Input(shape=(None, emb_dim))\n",
    "\n",
    "    # outputs are homology probabilities \n",
    "    output = SymmetricBilinearReduction(reduced_dim,\n",
    "                                        dropout, \n",
    "                                        use_attention_scores = True)(emb1, emb2)\n",
    "\n",
    "    # construct a model and compile for a standard binary classification task\n",
    "    model = tf.keras.models.Model(inputs=[emb1, emb2], outputs=output)\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-2,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=0.9)\n",
    "\n",
    "    model.compile(loss=masked_crossentropy, \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b45ecd2a-736e-40de-b5f5-6fd7025028b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:09:53.346297Z",
     "iopub.status.busy": "2023-05-11T06:09:53.346064Z",
     "iopub.status.idle": "2023-05-11T20:44:17.545963Z",
     "shell.execute_reply": "2023-05-11T20:44:17.545065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10000/10000 [==============================] - 5415s 541ms/step - loss: 1.2225 - categorical_accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "10000/10000 [==============================] - 5295s 530ms/step - loss: 1.0855 - categorical_accuracy: 0.9261\n",
      "Epoch 3/10\n",
      "10000/10000 [==============================] - 5172s 517ms/step - loss: 1.0368 - categorical_accuracy: 0.9285\n",
      "Epoch 4/10\n",
      "10000/10000 [==============================] - 5135s 514ms/step - loss: 1.0259 - categorical_accuracy: 0.9292\n",
      "Epoch 5/10\n",
      "10000/10000 [==============================] - 5202s 520ms/step - loss: 1.0166 - categorical_accuracy: 0.9296\n",
      "Epoch 6/10\n",
      "10000/10000 [==============================] - 5247s 525ms/step - loss: 1.0211 - categorical_accuracy: 0.9292\n",
      "Epoch 7/10\n",
      "10000/10000 [==============================] - 5265s 526ms/step - loss: 1.0173 - categorical_accuracy: 0.9294\n",
      "Epoch 8/10\n",
      "10000/10000 [==============================] - 5208s 521ms/step - loss: 1.0187 - categorical_accuracy: 0.9290\n",
      "Epoch 9/10\n",
      "10000/10000 [==============================] - 5251s 525ms/step - loss: 1.0139 - categorical_accuracy: 0.9296\n",
      "Epoch 10/10\n",
      "10000/10000 [==============================] - 5271s 527ms/step - loss: 1.0180 - categorical_accuracy: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: esm/bilinear_form_model_pfam_attention/assets\n"
     ]
    }
   ],
   "source": [
    "full_ds = make_dataset(a, batch_size)\n",
    "final_model = make_model(reduced_dim = 64, dropout = 0.2)\n",
    "final_model.fit(full_ds, epochs=10, steps_per_epoch=10000)\n",
    "final_model.save(f\"{prot_model}/bilinear_form_model_pfam_attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c6d55-0864-4e71-b45b-5624ad358e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"esm/bilinear_form_model_pfam_attention\", \n",
    "                                  custom_objects = {\"SymmetricBilinearReduction\" : SymmetricBilinearReduction, \n",
    "                                                    \"masked_crossentropy\" : masked_crossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9baf17-b09c-42c2-9c2b-9b029c37e02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"esm/bilinear_form_model_pfam_attention/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455d7e4-f2d8-4ad5-9540-0ea992a136a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
